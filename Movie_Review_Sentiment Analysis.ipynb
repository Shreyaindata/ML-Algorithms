{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-vUcn7eR68o"
      },
      "outputs": [],
      "source": [
        "# IMPORT LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "NMo7jTntSQu2",
        "outputId": "5244c0e7-ed7d-4cbc-dc18-dffd0a5dd65b"
      },
      "outputs": [],
      "source": [
        "# READ THE DATA\n",
        "df=pd.read_csv('IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3hmcHLu7SZFr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "8NBPE1hVSaKk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['review'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri65QQfWSvJo"
      },
      "outputs": [],
      "source": [
        "# Will work on 10000 rows as the data is taking more time\n",
        "\n",
        "#data cleaning\n",
        "\n",
        "#1.Remove HTML tags\n",
        "#2.Converting everything into lower case\n",
        "#3.Remove stop words - like, and, because, I , am\n",
        "#4.Removing special character\n",
        "#5.Stemming "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "526lYasoTGJO"
      },
      "outputs": [],
      "source": [
        "df1=df.sample(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "hIiltTV-TKHz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1000 entries, 34938 to 29184\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     1000 non-null   object\n",
            " 1   sentiment  1000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 23.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aTVDzP3eTMoV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "2wyRw7VETOfF"
      },
      "outputs": [],
      "source": [
        "#Converting the output into 1 and 0 as it should be in numerical format\n",
        "df1['sentiment'] = df1['sentiment'].map({'positive': '1', 'negative': '0'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "yN7AXlbZVG4M"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"This show is beautifully done. When it first came out I though it nothing more than a light-hearted family comedy with quite a few good one-liners. It seemed to express many families really well too, with different concepts of both parent and child, however, like I said, I never thought any more of it then a good watch on an evening. However, my view was shot out the other window when the tragic death of the fantastically funny John Ritter accrued. The programme stood it's ground and really commended the characters life in a very sensitive way that also touched the hearts of all the admire res of John Ritter, a fantastic actor with the talent to do anything. When the show aired after Ritters passing, I really wanted to just give my dad a hug and let him know how much he meant to me. I thought this shone threw the acting talents of the three children, particularly that of Bridget's character, who was worried of the last words she said to him. It reminded me that no matter what horrible things I say to my dad, I don't mean them and it's very important that he knows this. Great Show\""
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['review'].iloc[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA1j0VUeUSJA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"This show is beautifully done. When it first came out I though it nothing more than a light-hearted family comedy with quite a few good one-liners. It seemed to express many families really well too, with different concepts of both parent and child, however, like I said, I never thought any more of it then a good watch on an evening. However, my view was shot out the other window when the tragic death of the fantastically funny John Ritter accrued. The programme stood it's ground and really commended the characters life in a very sensitive way that also touched the hearts of all the admire res of John Ritter, a fantastic actor with the talent to do anything. When the show aired after Ritters passing, I really wanted to just give my dad a hug and let him know how much he meant to me. I thought this shone threw the acting talents of the three children, particularly that of Bridget's character, who was worried of the last words she said to him. It reminded me that no matter what horrible things I say to my dad, I don't mean them and it's very important that he knows this. Great Show\""
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To remove html tags\n",
        "\n",
        "import re\n",
        "clean = re.compile('<.*?>')\n",
        "re.sub(clean, '', df1.iloc[5].review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU1Obkz_VwM2"
      },
      "outputs": [],
      "source": [
        "# CREATING FUNCTION FOR REMOVING THE HTML TAGS\n",
        "\n",
        "import re\n",
        "def clean_htmltags(text):\n",
        "  clean = re.compile('<.*?>')\n",
        "  return re.sub(clean, '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XkFF-IUOWDSN"
      },
      "outputs": [],
      "source": [
        "df1['review']=df1['review'].apply(clean_htmltags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "EUtU6rYVWI1W"
      },
      "outputs": [],
      "source": [
        "# Convert text to lower case\n",
        "\n",
        "def convert_lower(text):\n",
        "  return text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "hCKghR0WWaw7"
      },
      "outputs": [],
      "source": [
        "df1['review']=df1['review'].apply(convert_lower)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "21MAJd0OWrJq"
      },
      "outputs": [],
      "source": [
        "# Function to remove special characters\n",
        "\n",
        "def remove_special_char(text):\n",
        "  text=re.sub('[^a-zA-Z0-9]',' ',text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "yE2WqiJnXxAD",
        "outputId": "743ab8e9-1834-48d5-b9f7-c5513d1b9064"
      },
      "outputs": [],
      "source": [
        "df1['review']=df1['review'].apply(remove_special_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2hsKl4_YbXQ"
      },
      "outputs": [],
      "source": [
        "# remove stop words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCwozpZ8YkR-"
      },
      "outputs": [],
      "source": [
        "# FUNCTION TO REMOVE THE STOP WORDS\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  new_text=[]\n",
        "  for i in text.split():\n",
        "    if i not in stopwords.words('english'):\n",
        "      new_text.append(i)\n",
        "  y=new_text[:]\n",
        "  new_text.clear()\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ePxTyZxQZ9nc",
        "outputId": "de7b8634-7712-4fdc-9b83-aeb1e5229cd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\shsood\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "df1['review']=df1['review'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-Mb3AC3gMV2"
      },
      "outputs": [],
      "source": [
        "# Perform Stemming\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUjDvn1mgrP8"
      },
      "outputs": [],
      "source": [
        "# FUNCTION TO PERFORM STEMMING\n",
        "\n",
        "y=[]\n",
        "\n",
        "def perform_stemming(text):\n",
        "  for i in text:\n",
        "    y.append(ps.stem(i))\n",
        "  z=y[:]\n",
        "  y.clear()\n",
        "  return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "OFzCV5djgpZ3"
      },
      "outputs": [],
      "source": [
        "df1['review']=df1['review'].apply(perform_stemming)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Xu4BSy-yhCmp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34938    [got, interest, movi, somebodi, made, beauti, ...\n",
              "12728    [worst, movi, ive, ever, seen, seen, lot, movi...\n",
              "43062    [johnson, fan, undoubtedli, worst, movi, done,...\n",
              "12859    [realli, enjoy, particular, product, mikado, p...\n",
              "36594    [american, pie, beta, hous, 6th, american, pie...\n",
              "                               ...                        \n",
              "7829     [film, less, year, soviet, withdraw, afghanist...\n",
              "40157    [use, love, muppet, muppet, movi, great, muppe...\n",
              "6009     [death, colleg, campu, appear, suicid, actual,...\n",
              "26666    [possibl, get, wors, probabl, steven, seagal, ...\n",
              "29184    [love, tv, show, hook, first, time, saw, wish,...\n",
              "Name: review, Length: 1000, dtype: object"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['review']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1DPbPEehqiu"
      },
      "outputs": [],
      "source": [
        "# Join back the list\n",
        "\n",
        "def join_back(list_input):\n",
        "  return \" \".join(list_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "xO6nXR4fhvFi"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34938</th>\n",
              "      <td>got interest movi somebodi made beauti video b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12728</th>\n",
              "      <td>worst movi ive ever seen seen lot movi friend ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43062</th>\n",
              "      <td>johnson fan undoubtedli worst movi done anybod...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12859</th>\n",
              "      <td>realli enjoy particular product mikado produc ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36594</th>\n",
              "      <td>american pie beta hous 6th american pie movi s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7829</th>\n",
              "      <td>film less year soviet withdraw afghanistan sub...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40157</th>\n",
              "      <td>use love muppet muppet movi great muppet caper...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6009</th>\n",
              "      <td>death colleg campu appear suicid actual cover ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26666</th>\n",
              "      <td>possibl get wors probabl steven seagal get wel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29184</th>\n",
              "      <td>love tv show hook first time saw wish act touc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "34938  got interest movi somebodi made beauti video b...         0\n",
              "12728  worst movi ive ever seen seen lot movi friend ...         0\n",
              "43062  johnson fan undoubtedli worst movi done anybod...         0\n",
              "12859  realli enjoy particular product mikado produc ...         1\n",
              "36594  american pie beta hous 6th american pie movi s...         0\n",
              "...                                                  ...       ...\n",
              "7829   film less year soviet withdraw afghanistan sub...         1\n",
              "40157  use love muppet muppet movi great muppet caper...         0\n",
              "6009   death colleg campu appear suicid actual cover ...         0\n",
              "26666  possibl get wors probabl steven seagal get wel...         0\n",
              "29184  love tv show hook first time saw wish act touc...         1\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1['review']=df1['review'].apply(join_back)\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq-qfhS4jHfE"
      },
      "outputs": [],
      "source": [
        "# TO CREATE A COLUMNS OF THE DISTICT WORDS\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "eFLWLVTmjqag",
        "outputId": "0fd14652-2dee-4c03-e050-b848db6403a1"
      },
      "outputs": [],
      "source": [
        "X=cv.fit_transform(df1['review']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "J-i307enj3A7",
        "outputId": "467128a6-f580-46a5-b793-12eea2b2b765"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 12766)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "tX-40htGj76p"
      },
      "outputs": [],
      "source": [
        "y=df1.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "udeKtYP9j-R2",
        "outputId": "b3bb81df-939a-49d3-95a4-c720b7988eb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ZU4Ei83akahs"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ZafQs3HBlB6F"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "-4wEodoolfP4"
      },
      "outputs": [],
      "source": [
        "clf1=GaussianNB()\n",
        "clf2=MultinomialNB()\n",
        "clf3=BernoulliNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "qeopRrWtlrDC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GaussianNB()\n",
            "MultinomialNB()\n",
            "BernoulliNB()\n"
          ]
        }
      ],
      "source": [
        "print(clf1.fit(X_train,y_train))\n",
        "print(clf2.fit(X_train,y_train))\n",
        "print(clf3.fit(X_train,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QI0-OV8HlzvE",
        "outputId": "6deae81c-3324-4033-f55d-38e796103cfb"
      },
      "outputs": [],
      "source": [
        "# MAKING PREDICTIONS ON ALL THE MODELS\n",
        "y_pred1=clf1.predict(X_test)\n",
        "y_pred2=clf2.predict(X_test)\n",
        "y_pred3=clf3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "sM77SVOomBDs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "RXAph12umGtz",
        "outputId": "5e42309e-525f-47d6-96a8-18f1d05feebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200,)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rZm18w7mN1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gaussian 0.625\n",
            "Multinominal 0.775\n",
            "Bernoulli 0.795\n"
          ]
        }
      ],
      "source": [
        "# CHECKING THE ACCURACY\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Gaussian\",accuracy_score(y_test,y_pred1))\n",
        "print(\"Multinominal\",accuracy_score(y_test,y_pred2))\n",
        "print(\"Bernoulli\",accuracy_score(y_test,y_pred3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "z4-lif96m0DQ",
        "outputId": "05c67d57-366a-4fb0-886b-716ac43cc655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gaussian 0.68\n",
            "Multinominal 0.805\n",
            "Bernoulli 0.795\n"
          ]
        }
      ],
      "source": [
        "# To improve accuracy we can pass max_features in the Countvectorizer\n",
        "# Now we will have 1000 columns where the words are repeating most of the time.\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(max_features=1000)\n",
        "X=cv.fit_transform(df1['review']).toarray()\n",
        "y=df1.iloc[:,-1].values\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=24)\n",
        "clf1=GaussianNB()\n",
        "clf2=MultinomialNB()\n",
        "clf3=BernoulliNB()\n",
        "clf1.fit(X_train,y_train)\n",
        "clf2.fit(X_train,y_train)\n",
        "clf3.fit(X_train,y_train)\n",
        "y_pred1=clf1.predict(X_test)\n",
        "y_pred2=clf2.predict(X_test)\n",
        "y_pred3=clf3.predict(X_test)\n",
        "print(\"Gaussian\",accuracy_score(y_test,y_pred1))\n",
        "print(\"Multinominal\",accuracy_score(y_test,y_pred2))\n",
        "print(\"Bernoulli\",accuracy_score(y_test,y_pred3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
